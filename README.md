# Projects

1. AI ASSISTANT:

	This project is an AI-powered chatbot built using the Natural Language Toolkit (NLTK) in Python. The chatbot is designed to read text data from a text file and answer questions based on the information contained within the file. The chatbot uses cosine similarity to map the user's question to the most appropriate answer in the text file. This approach enables the chatbot to provide relevant and accurate responses to user questions, making it a useful tool for automating customer service or providing quick access to information. Overall, this project demonstrates how natural language processing techniques can be used to build powerful AI-powered chatbots that can be customized to specific use cases.

	Demo : https://portfolioharshil.pythonanywhere.com

2. BudgetBuddy:

	This project is an Amazon price notifier that allows users to set a target price for a product and receive email notifications when the price drops below that threshold. The program works by scraping the product's price data from Amazon's website, comparing it to the user's desired price, and sending an email notification if the current price meets the criteria.

	This project can be a useful tool for users who want to monitor the prices of products on Amazon and get notified when they drop to a desired level. It can help users save money by allowing them to purchase products at a lower price and avoid overpaying for products.

	The code is written in Python and uses web scraping techniques to extract data from Amazon's website. It also uses email functionality to send notifications to the user when the target price has been met. The project can be customized to work with any Amazon product and allows users to set their own target prices and notification preferences.

	Overall, this project provides a practical solution for users who want to stay informed about the prices of their favorite products on Amazon and make informed purchasing decisions.

3. Analysis and Prediction of Air Quality in India:

	The Analysis and Prediction of Air Quality in India project utilizes data from the Central Pollution Control Board to analyze and predict air quality in India. The project involved extensive data pre-processing to ensure data cleanliness.

	The project aimed to achieve two primary objectives. Firstly, the team performed data analysis to identify useful insights such as the impact of the lockdown on air quality in major cities in India during 2020-2021. The analysis compared two scenarios: one with the lockdown in place and another without the lockdown.

	Secondly, the team used the latest time-series algorithms, including ARIMA, Prophet, LSTM, and Exponential Smoothing, to predict air quality data for 2021 and 2022. The project was later integrated with the Dash framework, which allowed the creation of interactive dashboards with visualizations using Plotly.

	This project is a significant contribution to the field of air quality analysis and prediction in India, and the insights generated can be helpful for policymakers and environmental agencies in decision-making.

4. ATM Interface:

	The ATM Interface in Java is a software program that emulates the functionality of an ATM. The program allows users to perform standard banking transactions, such as withdrawing cash, checking account balances, transferring funds, and changing PINs, among others.

	Java was chosen as the programming language for this project because of its robustness, platform independence, and object-oriented nature. Java is a highly secure language and is widely used in enterprise applications that require high levels of reliability and security. It also offers a rich set of libraries and frameworks that can be used to build complex applications efficiently.

5. Smart Attendance:

	This project is an Automated Attendance System developed using Python and Computer Vision that utilizes image recognition technology to capture and register a student's face and confirm their identity while marking attendance. This system eliminates the traditional attendance system of calling out roll numbers, which is time-consuming and hectic.

	The script automatically creates an Excel sheet based on the timetable of the day, and when a student's identity is confirmed, the script automatically marks their attendance on that sheet. For each attendance, the script records the student's name, the time the attendance was marked, how late the student was for the lecture, and the class teacher.

	The project generates a new Excel sheet for each day of the week, providing a specific sheet for every day, and thus making it easy to track the attendance of each student on a daily basis.

	In the future, data scientists can use these sheets to analyze the performance of each student on a monthly basis, making it easy to identify students who need additional help and to assess the overall performance of the class. Overall, this Automated Attendance System is a modern and efficient approach to tracking attendance, making it easier for both students and teachers alike.

6. Fundus Vision:

	This project utilizes transfer learning to develop a model that can classify fundus images of the eye as either having cataracts or being normal. The model used is VGG19, which has been integrated with Flask to create a website where users can upload an image of the fundus of the eye and run the model.

	When the user clicks on "Run Model," the uploaded JPEG/JPG image is converted into a machine-readable format, and the VGG19 model is triggered to classify the image as either having cataracts or being normal.

	This project has potential for use in healthcare and could assist doctors in diagnosing cataracts early on. The website is easy to use and accessible, making it an efficient tool for early detection of cataracts.

	Demo : https://drive.google.com/file/d/1Fa3c8A-tvAJblfip-2vZMkzbxDllQVCA/view?usp=share_link

7. NewsGuardian:

	This project utilizes Natural Language Processing (NLP) to classify news articles as either fake or not. The model has been trained on a large dataset of both fake and not fake news articles, allowing it to learn the key differences between them.

	To use the model, a user inputs a news article, and the model analyzes the language and content of the article to classify it as either fake or not. This project has the potential to be an important tool for identifying and combatting fake news, which is becoming increasingly prevalent in today's media landscape.

	Overall, this project demonstrates the power of NLP in identifying patterns in language and content, and how these patterns can be used to classify news articles and other text-based content.
